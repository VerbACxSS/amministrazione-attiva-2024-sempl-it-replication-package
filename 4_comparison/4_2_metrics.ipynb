{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9yWJNLIx6_"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tSDf1n7iIJo_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\Desktop\\verbacxss done\\cb2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\marco\\Desktop\\verbacxss done\\cb2\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from italian_ats_evaluator import TextAnalyzer, SimplificationAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4579,
     "status": "ok",
     "timestamp": 1716393383226,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "vS3LX1H9INnq",
    "outputId": "b7ce5e1f-2340-476f-92cc-8cc000fa266c"
   },
   "outputs": [],
   "source": [
    "TEXTS = ['human1', 'human2', 'gpt3_5', 'gpt4', 'gemini', 'llama3', 'phi3', 'semplit_mt5', 'semplit_umt5', 'semplit_gpt2_small_italian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvcgTTzMtJre"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716393383660,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "hiRDCeoejAQB",
    "outputId": "cc48f935-f71a-4b58-e4a6-a7d43e084826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(f\"./texts/original.csv\", encoding=\"utf-8\")\n",
    "original_df = original_df[['original_text', 'document', 'paragraph_index']]\n",
    "original_df = original_df.sort_values(by=['document', 'paragraph_index'])\n",
    "original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1716393384695,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "xAZeNGxTefo6",
    "outputId": "33b48c9e-48c4-4c56-d07f-279b0fee1588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human1\n",
      "(619, 4)\n",
      "human2\n",
      "(619, 4)\n",
      "gpt3_5\n",
      "(619, 4)\n",
      "gpt4\n",
      "(619, 4)\n",
      "gemini\n",
      "(619, 4)\n",
      "llama3\n",
      "(619, 4)\n",
      "phi3\n",
      "(619, 4)\n",
      "semplit_mt5\n",
      "(619, 4)\n",
      "semplit_umt5\n",
      "(619, 4)\n",
      "semplit_gpt2_small_italian\n",
      "(619, 4)\n"
     ]
    }
   ],
   "source": [
    "dfs_map = dict()\n",
    "for TEXT in TEXTS:\n",
    "  print(TEXT)\n",
    "  tmp_df = pd.read_csv(f\"./texts/{TEXT}.csv\", encoding=\"utf-8\")\n",
    "  tmp_df = tmp_df[['original_text', 'document', 'paragraph_index', 'simplified_text']]\n",
    "  tmp_df = tmp_df[(tmp_df['document'] != '99bdc9fdd8097f067f77cb220074b1b5') | (tmp_df['paragraph_index'] <= 80)]\n",
    "  tmp_df = tmp_df.rename(columns={\"simplified_text\": f\"{TEXT}_text\"})\n",
    "  tmp_df = tmp_df.sort_values(by=['document', 'paragraph_index'])\n",
    "  print(tmp_df.shape)\n",
    "  dfs_map[TEXT] = tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4gMjfmyJhK1"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22008,
     "status": "ok",
     "timestamp": 1716393406701,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "tumwWNSDwzgc",
    "outputId": "58786b9a-063e-40cd-d461-201fa02ff692"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:05<00:00, 108.52it/s]\n"
     ]
    }
   ],
   "source": [
    "original_metrics = []\n",
    "original_raw_data = []\n",
    "for row in tqdm(original_df.to_dict(orient=\"records\")):\n",
    "  result = TextAnalyzer(row[\"original_text\"])\n",
    "  original_metrics.append({\n",
    "    'document': row['document'],\n",
    "    'paragraph_index': row['paragraph_index'],\n",
    "    'original_text': row['original_text'],\n",
    "    # Basic\n",
    "    'original_n_tokens': result.basic.n_tokens,\n",
    "    'original_n_tokens_all': result.basic.n_tokens_all,\n",
    "    'original_n_chars': result.basic.n_chars,\n",
    "    'original_n_chars_all': result.basic.n_chars_all,\n",
    "    'original_n_syllables': result.basic.n_syllables,\n",
    "    'original_n_words': result.basic.n_words,\n",
    "    'original_n_unique_lemmas': result.basic.n_unique_lemmas,\n",
    "    'original_n_sentences': result.basic.n_sentences,\n",
    "    # Pos\n",
    "    'original_n_other': result.pos.n_other,\n",
    "    'original_n_nouns': result.pos.n_nouns,\n",
    "    'original_n_verbs': result.pos.n_verbs,\n",
    "    'original_n_number': result.pos.n_number,\n",
    "    'original_n_symbols': result.pos.n_symbols,\n",
    "    'original_n_adverbs': result.pos.n_adverbs,\n",
    "    'original_n_articles': result.pos.n_articles,\n",
    "    'original_n_pronouns': result.pos.n_pronouns,\n",
    "    'original_n_particles': result.pos.n_particles,\n",
    "    'original_n_adjectives': result.pos.n_adjectives,\n",
    "    'original_n_prepositions': result.pos.n_prepositions,\n",
    "    'original_n_proper_nouns': result.pos.n_proper_nouns,\n",
    "    'original_n_punctuations': result.pos.n_punctuations,\n",
    "    'original_n_interjections': result.pos.n_interjections,\n",
    "    'original_n_coordinating_conjunctions': result.pos.n_coordinating_conjunctions,\n",
    "    'original_n_subordinating_conjunctions': result.pos.n_subordinating_conjunctions,\n",
    "    # Verbs\n",
    "    'original_n_active_verbs': result.verbs.n_active_verbs,\n",
    "    'original_n_passive_verbs': result.verbs.n_passive_verbs,\n",
    "    # Readability\n",
    "    'original_ttr': result.readability.ttr,\n",
    "    'original_gulpease': result.readability.gulpease,\n",
    "    'original_flesch_vacca': result.readability.flesch_vacca,\n",
    "    'original_lexical_density': result.readability.lexical_density,\n",
    "    # VdB\n",
    "    'original_n_vdb': result.vdb.n_vdb_tokens,\n",
    "    'original_n_vdb_fo': result.vdb.n_vdb_fo_tokens,\n",
    "    'original_n_vdb_au': result.vdb.n_vdb_au_tokens,\n",
    "    'original_n_vdb_ad': result.vdb.n_vdb_ad_tokens,\n",
    "  })\n",
    "  original_raw_data.append({\n",
    "      'document': row['document'],\n",
    "      'paragraph_index': row['paragraph_index'],\n",
    "      'original_text': row['original_text'],\n",
    "      'original_tokens': result.basic.tokens,\n",
    "      'original_lemmas': result.basic.lemmas\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120314,
     "status": "ok",
     "timestamp": 1716393527012,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "WFI47tGm9BKJ",
    "outputId": "393bd05e-644f-4d6d-de57-98e984d5c318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/619 [00:00<?, ?it/s]c:\\Users\\marco\\Desktop\\verbacxss done\\cb2\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\marco\\Desktop\\verbacxss done\\cb2\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\marco\\Desktop\\verbacxss done\\cb2\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\marco\\Desktop\\verbacxss done\\cb2\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 619/619 [00:26<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:22<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt3_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:24<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:23<00:00, 26.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:24<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:24<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:23<00:00, 26.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semplit_mt5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:22<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semplit_umt5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:22<00:00, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semplit_gpt2_small_italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:23<00:00, 26.84it/s]\n"
     ]
    }
   ],
   "source": [
    "simplified_metrics = {TEXT:[] for TEXT in TEXTS}\n",
    "simplified_raw_data = {TEXT:[] for TEXT in TEXTS}\n",
    "for TEXT in TEXTS:\n",
    "  print(TEXT)\n",
    "  for row in tqdm(dfs_map[TEXT].to_dict(orient=\"records\")):\n",
    "    result = SimplificationAnalyzer(row[\"original_text\"], row[f\"{TEXT}_text\"])\n",
    "\n",
    "    simplified_metrics[TEXT].append({\n",
    "      'document': row['document'],\n",
    "      'paragraph_index': row['paragraph_index'],\n",
    "      'original_text': row['original_text'],\n",
    "      f'{TEXT}_text': row[f'{TEXT}_text'],\n",
    "      # Basic\n",
    "      f'{TEXT}_n_tokens': result.simplified.basic.n_tokens,\n",
    "      f'{TEXT}_n_tokens_all': result.simplified.basic.n_tokens_all,\n",
    "      f'{TEXT}_n_chars': result.simplified.basic.n_chars,\n",
    "      f'{TEXT}_n_chars_all': result.simplified.basic.n_chars_all,\n",
    "      f'{TEXT}_n_syllables': result.simplified.basic.n_syllables,\n",
    "      f'{TEXT}_n_words': result.simplified.basic.n_words,\n",
    "      f'{TEXT}_n_unique_lemmas': result.simplified.basic.n_unique_lemmas,\n",
    "      f'{TEXT}_n_sentences': result.simplified.basic.n_sentences,\n",
    "      # Pos\n",
    "      f'{TEXT}_n_other': result.simplified.pos.n_other,\n",
    "      f'{TEXT}_n_nouns': result.simplified.pos.n_nouns,\n",
    "      f'{TEXT}_n_verbs': result.simplified.pos.n_verbs,\n",
    "      f'{TEXT}_n_number': result.simplified.pos.n_number,\n",
    "      f'{TEXT}_n_symbols': result.simplified.pos.n_symbols,\n",
    "      f'{TEXT}_n_adverbs': result.simplified.pos.n_adverbs,\n",
    "      f'{TEXT}_n_articles': result.simplified.pos.n_articles,\n",
    "      f'{TEXT}_n_pronouns': result.simplified.pos.n_pronouns,\n",
    "      f'{TEXT}_n_particles': result.simplified.pos.n_particles,\n",
    "      f'{TEXT}_n_adjectives': result.simplified.pos.n_adjectives,\n",
    "      f'{TEXT}_n_prepositions': result.simplified.pos.n_prepositions,\n",
    "      f'{TEXT}_n_proper_nouns': result.simplified.pos.n_proper_nouns,\n",
    "      f'{TEXT}_n_punctuations': result.simplified.pos.n_punctuations,\n",
    "      f'{TEXT}_n_interjections': result.simplified.pos.n_interjections,\n",
    "      f'{TEXT}_n_coordinating_conjunctions': result.simplified.pos.n_coordinating_conjunctions,\n",
    "      f'{TEXT}_n_subordinating_conjunctions': result.simplified.pos.n_subordinating_conjunctions,\n",
    "      # Verbs\n",
    "      f'{TEXT}_n_active_verbs': result.simplified.verbs.n_active_verbs,\n",
    "      f'{TEXT}_n_passive_verbs': result.simplified.verbs.n_passive_verbs,\n",
    "      # Readability\n",
    "      f'{TEXT}_ttr': result.simplified.readability.ttr,\n",
    "      f'{TEXT}_gulpease': result.simplified.readability.gulpease,\n",
    "      f'{TEXT}_flesch_vacca': result.simplified.readability.flesch_vacca,\n",
    "      f'{TEXT}_lexical_density': result.simplified.readability.lexical_density,\n",
    "      # VdB\n",
    "      f'{TEXT}_n_vdb': result.simplified.vdb.n_vdb_tokens,\n",
    "      f'{TEXT}_n_vdb_fo': result.simplified.vdb.n_vdb_fo_tokens,\n",
    "      f'{TEXT}_n_vdb_au': result.simplified.vdb.n_vdb_au_tokens,\n",
    "      f'{TEXT}_n_vdb_ad': result.simplified.vdb.n_vdb_ad_tokens,\n",
    "      # Similariy\n",
    "      f'{TEXT}_semantic_similarity': result.similarity.semantic_similarity,\n",
    "      # Diff\n",
    "      f'{TEXT}_editdistance': result.diff.editdistance,\n",
    "      f'{TEXT}_n_added_tokens': result.diff.n_added_tokens,\n",
    "      f'{TEXT}_n_deleted_tokens': result.diff.n_deleted_tokens,\n",
    "      f'{TEXT}_n_added_vdb_tokens': result.diff.n_added_vdb_tokens,\n",
    "      f'{TEXT}_n_deleted_vdb_tokens': result.diff.n_deleted_vdb_tokens,\n",
    "    })\n",
    "    simplified_raw_data[TEXT].append({\n",
    "      'document': row['document'],\n",
    "      'paragraph_index': row['paragraph_index'],\n",
    "      'original_text': row['original_text'],\n",
    "      f'{TEXT}_text': row[f'{TEXT}_text'],\n",
    "      f'{TEXT}_tokens': result.simplified.basic.tokens,\n",
    "      f'{TEXT}_lemmas': result.simplified.basic.lemmas\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z5c_GY-K-ff"
   },
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vye69A8QmA6_"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(original_metrics).to_csv(f\"./texts_with_metrics/original.csv\", index=False)\n",
    "json.dump(original_raw_data, open(f\"./texts_with_metrics/original.json\", 'w', encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1716393527526,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "v7zdA7MviVLW",
    "outputId": "54b6c5d3-6ee3-48d9-dbe4-aacfa0871955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human1\n",
      "human2\n",
      "gpt3_5\n",
      "gpt4\n",
      "gemini\n",
      "llama3\n",
      "phi3\n",
      "semplit_mt5\n",
      "semplit_umt5\n",
      "semplit_gpt2_small_italian\n"
     ]
    }
   ],
   "source": [
    "for TEXT in TEXTS:\n",
    "  print(TEXT)\n",
    "  pd.DataFrame(simplified_metrics[TEXT]).to_csv(f\"./texts_with_metrics/{TEXT}.csv\", index=False)\n",
    "  json.dump(simplified_raw_data[TEXT], open(f\"./texts_with_metrics/{TEXT}.json\", 'w', encoding=\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
